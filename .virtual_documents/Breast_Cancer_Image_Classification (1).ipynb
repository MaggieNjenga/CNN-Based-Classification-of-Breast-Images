


#Install the torchmetrics package for storing loss, evaluation metrics, etc.
!pip install lightning-utilities
!pip install torchmetrics --no-deps
#Install the torchinfo package for showing the network information
!pip install torchinfo --no-deps

import os
import numpy as np
import pandas as pd
import random
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import torch
import torch.nn as nn
import torchvision
from torchvision.transforms import v2
from torchvision.transforms.functional import to_pil_image
from torchmetrics import MeanMetric, Accuracy
from torchmetrics import ConfusionMatrix, Accuracy, Precision, Recall, F1Score
from torchinfo import summary


#make sure to change runtime to GPU
#Check if GPU is available
device = "cuda" if torch.cuda.is_available() else "mps" if torch.mps.is_available() else "cpu"
print(f"Using {device} device")








#data augmentation for train
train_transform = v2.Compose([
    v2.RandomHorizontalFlip(p=0.5), #Random horizontal flip
    v2.RandomResizedCrop(size=128, scale=(0.8, 1.0)), #random crop and resize
    v2.ToImage(), # Pytorch image format
    v2.ToDtype(torch.float32, scale=True), #convert to tensor
    v2.Normalize(mean=[0.485, 0.456, 0.406],
                 std=[0.229, 0.224, 0.225]) #normalize
])


#data augmentation for validation and test
eval_transform = v2.Compose([
    v2.Resize(128),
    v2.CenterCrop(128),#resize image to 224
    v2.ToImage(), # Pytorch image format
    v2.ToDtype(torch.float32, scale=True), #convert to tensor
    v2.Normalize(mean=[0.485, 0.456, 0.406],
                 std=[0.229, 0.224, 0.225]) #normalize
])


#Read datasets
train_set = torchvision.datasets.ImageFolder('/content/drive/MyDrive/data/train', transform=train_transform)
val_set = torchvision.datasets.ImageFolder('/content/drive/MyDrive/data/val', transform=eval_transform)
test_set = torchvision.datasets.ImageFolder('/content/drive/MyDrive/data/test', transform=eval_transform)


# Define the dataloaders for the training, validation, and test sets
train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)
val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False)
test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)


#Define classes
classes = ["Benign", "Malignant"]
num_class = len(classes)
print("Number of classes:", num_class)


print(train_set.class_to_idx)


print("Number of training samples:", len(train_set))
print("Number of validation samples:", len(val_set))
print("Number of test samples:", len(test_set))


from collections import Counter

def count_class_sample_number(dataset):
    # Get the labels directly from dataset targets
    labels = dataset.targets  # much faster than accessing dataset[i]
    counts = Counter(labels)
    for class_idx, count in counts.items():
        print(f"Class {dataset.classes[class_idx]} has {count} samples.")

count_class_sample_number(train_set)
count_class_sample_number(val_set)
count_class_sample_number(test_set)


# Function to count class samples in a dataset
def get_class_distribution(dataset):
    label_counts = Counter(dataset.targets)
    return {dataset.classes[class_idx]: count for class_idx, count in label_counts.items()}

# Get counts for each set
train_counts = get_class_distribution(train_set)
val_counts = get_class_distribution(val_set)
test_counts = get_class_distribution(test_set)

# Combine into one dict for plotting
import pandas as pd

df = pd.DataFrame({
    'Train': train_counts,
    'Validation': val_counts,
    'Test': test_counts
}).T  # Transpose for easier plotting

# Plot
ax = df.plot(kind='bar', figsize=(8, 5))
plt.title('Class Distribution Across Datasets')
plt.xlabel('Dataset')
plt.ylabel('Number of Images')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.legend(title='Class')
plt.tight_layout()
plt.show()


# Define denormalization transform
def denormalize(tensor):
  # Reshape to match image dimensions
  mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3, 1, 1)
  std = torch.tensor([0.229, 0.224, 0.225]).reshape(3, 1, 1)
  return tensor * std + mean # Reverse normalization

# Visualize one sample per class
def visualize_data(dataset, classes, transform=None):
    sample_images = []
    for class_i in range(len(classes)):
        for image_path, label in dataset.imgs:
            if label == class_i:
                image = Image.open(image_path)
                if transform:
                    image = transform(image)             # Apply transform
                    image = denormalize(image)           # Undo normalization
                    image = to_pil_image(image.clamp(0, 1)) # Convert to displayable image
                sample_images.append(image)
                break
    return sample_images

# Use the function
sample_images = visualize_data(train_set, classes, transform=train_transform)

# Show the images
fig, axes = plt.subplots(1, len(classes), figsize=(10, 3))
for i, axis in enumerate(axes.flat):
    axis.set_xticks([])
    axis.set_yticks([])
    axis.set_xlabel(classes[i], fontsize=12)
    axis.imshow(sample_images[i])
plt.tight_layout()
plt.show()


sample_untransform = visualize_data(train_set, classes)

# Show the images
fig, axes = plt.subplots(1, len(classes), figsize=(10, 3))
for i, axis in enumerate(axes.flat):
    axis.set_xticks([])
    axis.set_yticks([])
    axis.set_xlabel(classes[i], fontsize=12)
    axis.imshow(sample_images[i])
plt.tight_layout()
plt.show()








model = nn.Sequential(
    #convolutions & pooling layers
    nn.LazyConv2d(32, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(kernel_size=2),

    nn.LazyConv2d(64, kernel_size=3, stride=1, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(kernel_size=2),

    #flat tensor to vector
    nn.Flatten(),

    #fully-connected layers
    nn.LazyLinear(512),
    nn.ReLU(),

    nn.LazyLinear(256),
    nn.ReLU(),

    nn.LazyLinear(1)
)


#move model to GPU device
model = model.to(device)





#specify loss function (binary cross-entropy)
criteria = torch.nn.BCEWithLogitsLoss()

#specify optimizer (Adam) and learning rate= 0.01
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)





#a function for training one epoch
def train_one_epoch():
  #prepare for storing and loss accuracy
  losses = MeanMetric().to(device)
  acc = Accuracy(task='binary').to(device)
  model.train() #set model to train mode
  #a loop to iterate input(X) and label(Y) for all mini-batches
  for X, Y in train_dataloader:
    #move data to GPU device
    X = X.to(device)
    Y = Y.to(device).float().unsqueeze(1)
    optimizer.zero_grad() #reset optimizer
    preds = model(X) #model forward
    loss = criteria(preds, Y) #calculate loss
    loss.backward() #compute gradients via back propagation
    optimizer.step() #perform gradient descent
    preds = torch.sigmoid(preds)
    preds = (preds > 0.5).float()
    losses.update(loss, X.size(0)) #store loss per batch
    acc.update(preds, Y) # store accuracy per batch
  #return loss and accuracy for the epoch
  return losses.compute().item(), acc.compute().item()





# a function for validation one epoch
def validation_one_epoch():
  #prepare for storing loss and accuracy
  losses = MeanMetric().to(device)
  acc = Accuracy(task="binary").to(device)

  #set the model to validation mode
  model.eval()
  with torch.no_grad():
    #a loop to iterate input(X) and label(Y) FOR ALL MINIBATCHES
    for X, Y in val_dataloader:
      X = X.to(device)
      Y = Y.to(device).float().unsqueeze(1)

      preds=model(X)
      loss=criteria( preds, Y)
      preds = torch.sigmoid(preds)
      preds = (preds > 0.5).float()

      losses.update(loss, X.size(0))
      acc.update(preds, Y)
  return losses.compute().item(), acc.compute().item()


epochs = 10
#a loop for epochs
for i in range(0, epochs):
  train_loss, train_acc = train_one_epoch()
  val_loss, val_acc = validation_one_epoch()

  print("Epoch:", i, "| Train Loss:", train_loss, "| Train Accuracy", train_acc, "| Validation Loss", val_loss, "| Validation Accuracy", val_acc)


from torchsummary import summary
summary(model, input_size=(3, 128, 128))


!pip install torchviz
!apt install graphviz


from torchviz import make_dot

model = model.to("cpu")

x = torch.randn(1, 3, 128, 128)  # adjust input size
y = model(x)

# Generate graph
make_dot(y, params=dict(model.named_parameters())).render("custom_cnn_graph", format="png")


from IPython.display import Image
Image(filename="custom_cnn_graph.png")





# prepare for storing evaluation metrics
test_confusion_matrix=ConfusionMatrix(task="binary")
test_acc = Accuracy(task='binary')

model = model.to('cpu') # move the model back to CPU device
model.eval() # set model to evaluation mode

with torch.no_grad():
  for X, Y in test_dataloader:
    X = X.to('cpu')
    Y = Y.to('cpu').float().unsqueeze(1)

    preds = model(X) # model forward
    preds = torch.sigmoid(preds)
    preds = (preds > 0.5).float() # obtain the final predicted class

    # store loss and accuracy per batc
    test_confusion_matrix.update(preds, Y)
    test_acc.update(preds, Y)

   #print the results
  print("Confusion Matrix:\n", test_confusion_matrix.compute())
  print("Accuracy:", test_acc.compute().item())


cm = test_confusion_matrix.compute().numpy()
labels = ['Benign', 'Malignant']

plt.figure(figsize=(6, 5))
sns.heatmap(pd.DataFrame(cm, index=labels, columns=labels),
            annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


# prepare for storing evaluation metrics
test_acc = Accuracy(task='binary').to(device)
test_confusion_matrix=ConfusionMatrix(task="binary").to (device)
test_precision = Precision(task="binary", average="macro").to(device)
test_recall = Recall(task="binary", average="macro").to(device)
test_f1_score = F1Score (task="binary", average="macro").to (device)

model = model.to (device)
model.eval() #set model to evaluation mode

with torch.no_grad():
  for X, Y in test_dataloader:
    X = X.to(device)
    Y = Y.to(device).float().unsqueeze(1)
    preds = model(X) # model forward
    preds = torch.sigmoid(preds)
    preds = (preds > 0.5).float() # obtain the final predicted class

    # store loss and accuracy per batc
    test_confusion_matrix.update (preds, Y)
    test_acc.update(preds, Y)
    test_precision.update (preds, Y)
    test_recall.update (preds, Y)
    test_f1_score.update (preds, Y)

  # Print the results
  print("Confusion Matrix:\n", test_confusion_matrix.compute())
  print("Accuracy:", test_acc.compute().item())
  print("Precision:", test_precision.compute().item())
  print("Recall:", test_recall.compute().item())
  print("F1 Score:", test_f1_score.compute().item())





#get a pretrained resnet18
model = torchvision.models.resnet18(weights='IMAGENET1K_V1')


#Check the last layer name
print(model)


#add new layer/change the last layer
model.fc = nn.Linear(model.fc.in_features, 1)


#confirm the output matches number of classes
print(model)


#Move model to GPU
model = model.to(device)





#specify loss function (binary cross-entropy)
criteria = torch.nn.BCEWithLogitsLoss()

#specify optimizer (Adam) and learning rate= 0.01
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)





from tqdm import tqdm

#a function for training one epoch
def train_one_epoch(model, dataloader):
  #prepare for storing and loss accuracy
  losses = MeanMetric().to(device)
  acc = Accuracy(task='binary').to(device)
  model.train() #set model to train mode
  #a loop to iterate input(X) and label(Y) for all mini-batches
  for X, Y in tqdm(dataloader):
    #move data to GPU device
    X = X.to(device)
    Y = Y.to(device).float().unsqueeze(1)
    optimizer.zero_grad() #reset optimizer
    preds = model(X) #model forward
    loss = criteria(preds, Y) #calculate loss
    loss.backward() #compute gradients via back propagation
    optimizer.step() #perform gradient descent
    preds = torch.sigmoid(preds)
    preds = (preds > 0.5).float()
    losses.update(loss, X.size(0)) #store loss per batch
    acc.update(preds, Y) # store accuracy per batch
  #return loss and accuracy for the epoch
  return losses.compute().item(), acc.compute().item()





# a function for validation one epoch
def validation_one_epoch(model, dataloader):
  #prepare for storing loss and accuracy
  losses = MeanMetric().to(device)
  acc = Accuracy(task="binary").to(device)

  #set the model to validation mode
  model.eval()
  with torch.no_grad():
    #a loop to iterate input(X) and label(Y) FOR ALL MINIBATCHES
    for X, Y in tqdm(dataloader):
      X = X.to(device)
      Y = Y.to(device).float().unsqueeze(1)

      preds=model(X)
      loss=criteria( preds, Y)
      preds = torch.sigmoid(preds)
      preds = (preds > 0.5).float()

      losses.update(loss, X.size(0))
      acc.update(preds, Y)
  return losses.compute().item(), acc.compute().item()





#Prepare for storing loss and accuracy
history = pd.DataFrame() #store statistics for each epoch
epochs = 20 #number of epochs

#a loop for epochs
for i in range(0, epochs):
  #train one epoch
  train_loss, train_acc = train_one_epoch(model, train_dataloader)
  #validation one epoch
  val_loss, val_acc = validation_one_epoch(model, val_dataloader)
  #store and print loss and accuracy per epoch
  statistics = pd.DataFrame({
      'epoch': [i],
      'train_loss': [train_loss],
      'train_acc': [train_acc],
      'val_loss': [val_loss],
      'val_acc': [val_acc]
  })
  history = pd.concat([history, statistics], ignore_index=True)
  print(statistics.to_dict(orient="records")[0])


# Create a figure with two subplots (side by side)
plt.figure(figsize=(8, 3))
# Plot Loss Curve (Train + Validation)
plt.subplot(1, 2, 1) # 1 row, 2 columns, first plot
plt.plot (history["epoch"], history["train_loss"], label="Train", color="blue")
plt.plot (history["epoch"], history["val_loss"], label="Validation", color="red")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
# Plot Accuracy Curve (Train + Validation)
plt.subplot(1, 2, 2) # 1 row, 2 columns, second plot
plt.plot (history ["epoch"], history["train_acc"], label="Train", color="blue")
plt.plot (history ["epoch"], history["val_acc"], label="Validation", color="red")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
# Adjust layout and show the plots
plt.tight_layout()
plt.show()



# prepare for storing evaluation metrics
test_acc = Accuracy(task='binary').to(device)
test_confusion_matrix=ConfusionMatrix(task="binary").to (device)
test_precision = Precision(task="binary", average="macro").to(device)
test_recall = Recall(task="binary", average="macro").to(device)
test_f1_score = F1Score (task="binary", average="macro").to (device)

model = model.to (device)
model.eval() #set model to evaluation mode

with torch.no_grad():
  for X, Y in test_dataloader:
    X = X.to(device)
    Y = Y.to(device).float().unsqueeze(1)
    preds = model(X) # model forward
    preds = torch.sigmoid(preds)
    preds = (preds > 0.5).float() # obtain the final predicted class

    # store loss and accuracy per batc
    test_confusion_matrix.update (preds, Y)
    test_acc.update(preds, Y)
    test_precision.update (preds, Y)
    test_recall.update (preds, Y)
    test_f1_score.update (preds, Y)

  # Print the results
  print("Confusion Matrix:\n", test_confusion_matrix.compute())
  print("Accuracy:", test_acc.compute().item())
  print("Precision:", test_precision.compute().item())
  print("Recall:", test_recall.compute().item())
  print("F1 Score:", test_f1_score.compute().item())





# Define denormalization transform
def denormalize(tensor):

  # Reshape to match image dimensions
  mean = torch.tensor ([0.485, 0.456, 0.406]).reshape(3, 1, 1)
  std = torch.tensor ([0.229, 0.224, 0.225]).reshape(3, 1, 1)
  return tensor * std + mean # Reverse normalization

# shuffle the test data to have samples from all classes
test_dataloader = torch.utils.data.DataLoader (test_set, batch_size=32, shuffle=True)

# obtain one batch of test images
images, labels = next(iter(test_dataloader))

# move model to cpu
model = model.to('cpu')

# get sample outputs
model.eval()
with torch.no_grad():
  preds = model(images) # model forward
  preds = torch.sigmoid(preds)
  preds = (preds > 0.5).float() # obtain the final predicted class

# Create a 4x4 grid for displaying the images
fig, axes = plt.subplots(4, 4, figsize=(8, 8))
# Iterate over the images and display them in the grid
for idx, ax in enumerate (axes.flat):
  image = images[idx] # get one image
  image = denormalize(image) # denormalize
  # convert back to PIL image format
  image = to_pil_image(image.clamp(0, 1))
  ax.imshow(image) # Display the image
  ax.axis('off') # Hide the axes
  # Add title to the image
  #green: correct prediciton, red: incorrect prediction
  prediction = int(preds[idx].item())
  label = int(labels[idx].item())

  ax.set_title("{}".format(classes[prediction]), color = ("green" if prediction == label else "red"))

plt.tight_layout()
plt.show()

